# dat protocol WG (#NUMBER)

*DATE via IRC (#datprotocol)*

[Agenda discussion](https://github.com/datprotocol/working-group/issues/ISSUE_NUMBER)

## People

* pfrazee
* rangermauve
* bnewbold
* andrewosh
* mafintosh

## Agenda

- Quick update of what everyone is up to
- Discuss migration to new hyperdrive / hyperswarm
  - Discuss settling on a abstract dat interface https://github.com/datprotocol/DEPs/issues/60
  - Discuss roadmap for Daemon and how it'll work
  - Standardize where hypercores are supposed to be stored.
- We should discuss formalizing how the meetings should be organized (and by who) as well as reducing some of the boilerplate.
- It'd be cool if more people in the Dat ecosystem had a roadmap for what they're working on so that the community can be up to date.

## Summary/Review of Previous Meeting

* [Meeting notes](https://github.com/datprotocol/working-group/blob/master/meeting-notes/24-08May2019.md)
* [Action Items](https://github.com/datprotocol/working-group/issues/53)

## Meeting Notes

* What everyone is up to:
  * bnewbold: Working with https://qa.fatcat.wiki/
  * pfrazee: lots of beaker UI work, also doing some refactoring of the unwalled garden APIs. todo list for the 0.9 public beta is: * new daemon with hyperdrive 10, * new filesystem arch based on mounts, * new web apis, and * dat "remotes" integration. So I'm blocked on a couple items
  * andrewosh: Daemon work, the project grew a bit in scope recently from fuse to more general hyperdrive management
  * mafintosh: assisting andrewosh and making an updated archiver. Along with 1000 other things obvs ðŸ˜†
  * rangermauve: currently drafting up the Dat SDK and thinking about what the CLI and everything is gonna look like
* Migration to new hyperdrive / hyperswarm
  * rangermauve: Here's a graph about what the ecosystem ![Graph with parts modules tied together in a higharchy](https://user-images.githubusercontent.com/911495/59313505-5cf7f500-8c7f-11e9-914a-64b90c2dba17.png)
  * andrewosh's megastore could be the library
  * rangermauve: it looks like the megastore stuff is there so that the daemon can manage hypercores, but I was thinking it'd be good to have something more high level
  * andrewosh: main daemon API will be grpc-based (to keep things as close to the protos in hyperdrive as possible). should be easy to wrap with other higher-level APIs. it takes in a networking module as a peer dep -- can be anything that exposes `seed` and `unseed` pretty much
  * We should probably get hyperdiscovery to match that interface or vise versa so that hyperdiscovery will be a one-stop shop for replicationg "dat" stuff so that we can upgrade it in one spot
  * mafintosh: easier to use the swarm in megastore
  * rangermauve: need to build something on top of megastore and do the browser-compat at that level
  * pfrazee: unsure about making wire-protocol extensions first class
  * rangermauve: people building applications on Dat are making heavy use of them. Cabal is probably the most heavily developed Dat app at the moment and they're making use of multifeed which has extensions built in
  * pfrazee: should we be using peersockets instead of extension messages?
  * rangermauve: I think some use cases are better suited with peersockets, but for something like multifeed, extensions make more sense. They use it to say "Hey, here's some other hypercores that are related to this one" which would be really annoying to do through a side channel
* abstract-dat-interface / handling dats with corestores
  * mafintosh: hyperdrives are handled through corestors. The megastore can produce those. Thatâ€™s how you construct arbitrary data structures on top
  * rangermauve: multifeed and kappa-core will take a corestore as an argument and it'll handle the rest
  * rangermauve: corestores are the building block for data structures, megastore will produce corestores for those data structures and will manage networking and stuff
  * andrewosh: once there's a clear prototype showing how these all connect, things will be clearer. the current design behind this hyperdrive daemon (or hypercore/corestore daemon, depending on the API we decide on). shooting for a basic impl by the end of the week, actually, but let's say 2 for good measure. have a client library (so you don't have to work with grpc) and a simple CLI tool as well
* Standardize on where hypercores are stored
  * rangermauve: any strong opinions on where the hypercore data is going to be stored? I was thinking it'd be good to use something based on https://github.com/sindresorhus/env-paths#pathsdata and share it everywhere. been sketching up for the SDK so I can have backwards-compatible storage: https://github.com/RangerMauve/universal-dat-storage/blob/master/README.md . But that'll probably get reworked a bunch once the daemon is ready. I was thinking that with regards to the CLI and its folder sync, we could use a new `.dat` file inside the folder and have the metadata tracked inside the daemon.
* backwards-compatibility
  * andrewosh: the daemon can always inspect the metadata header and do special handling during drive initialization, but it needs a lot more thought
  * rangermauve: you could punt some of the backwards compat to the CLI, but not in the dat clone case
  * andrewosh the thinking so far has been to replace much of the work around files-as-files with a persistent, top-level "root hyperdrive" that acts as a home folder replacement
  * pfrazee: we'll need to support both though, the dat cli and the fuse. there's folder<->dat syncing code in beaker that we can look into reusing. moving the dat stack into a daemon makes the old random-access trick much more difficult to use
* daemon
  * rangermauve: The other thing that'd be nice to have in the daemon down the line is RPC for interacting with hyperdrives. Does somethign like that make sense in the daemon that hyperdivision are working on, or should we maybe have a higher level daemon for Beaker and the CLI to base off of?
  * andrewosh: that's on my plate for the first version of the daemon -- hyperdrive and fuse APIs
  * The hyperdrive API / PeerSockets / Hypercore API would all be useful for non-nodejs applications trying to embed Dat into their stack
* hyperswarm backwards-compatibility
  * rangermauve: Are you going to be using dat-swarm-defaults for the networking?
  * andrewosh: not sure, but any reasonable config options will be exposed to the CLI
  * mafintosh: will setup a dns service that runs hyperdht
  * pfrazee: the idea is that the existing DNS service will get replaced with a new one that wraps the dht

## ACTION ITEMS

* Create an issue for discussing extensions @rangermauve
* Create an issue to discuss MDNS backwards compatibility
* Create issue to discuss Daemon more
